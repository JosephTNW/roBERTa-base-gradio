{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import RobertaTokenizerFast, AutoModelForQuestionAnswering\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
    "# Change model to your path to the model folder
    "model = AutoModelForQuestionAnswering.from_pretrained(\"model\", local_files_only=True)\n",
    "\n",
    "# Create a question answering pipeline\n",
    "qa_pipeline = pipeline('question-answering', model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Example contexts and questions\n",
    "contexts = [\n",
    "    \"Learning from the roles of civet in SARS and camel in MERS, hunting for the animal source of 2019-nCoV and its more ancestral virus would be important for understanding the origin and evolution of this novel lineage B betacoronavirus. These findings provide the basis for starting further studies on the pathogenesis, and optimizing the design of diagnostic, antiviral and vaccination strategies for this emerging infection.\",\n",
    "    \"No credible evidence supporting claims of the laboratory engineering of SARS-CoV-2\",\n",
    "    \"The under-reporting was likely to have resulted in 469 (95% CI: 403&minus;540) unreported cases from 1 to 15 January 2020.\"\n",
    "]\n",
    "\n",
    "questions = [\n",
    "    \"What is important for understanding the origin and evolution of this novel lineage B betacoronavirus.\",  #NO. 0\n",
    "    \"What is the conclusion of this report?\",  #NO. 10\n",
    "    \"What was the result of under-reporting?\"  #NO. 2\n",
    "]\n",
    "\n",
    "# Get predictions for each context and question pair\n",
    "predictions = qa_pipeline(context=contexts, question=questions)\n",
    "\n",
    "# Print the predictions\n",
    "for i, prediction in enumerate(predictions):\n",
    "    print(f\"Context: {contexts[i]}\")\n",
    "    print(f\"Question: {questions[i]}\")\n",
    "    print(prediction)\n",
    "    print()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# using gradio\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def func(context, question):\n",
    "    result = qa_pipeline(question=question, context=context)\n",
    "    return result['answer']\n",
    "\n",
    "\n",
    "app = gr.Interface(fn=func, inputs=['textbox', 'text'], outputs='textbox', title='Question Answering bot',\n",
    "                   theme='dark-grass', description='Input context and question, then get answers!')\n"
   ],
   "id": "9aaa355cd086b379"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "app.launch(inline=False)",
   "id": "a7e71457b619f257"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
